[hosts]
# all information's for:
# jdk
# keyfree_login
# hostname
# hadoop
# spark
# no pg
hosts=192.168.130.196,192.168.130.197,192.168.130.123
# -----
localuser=ubuntu
localuser_passwd=123456
# -----
sudouser=ubuntu
sudouser_passwd=123456


[jdk]
# default install for the home directory
# no use sudouser
# add path for jdk
jdk_local_path=package/jdk-8u211-linux-x64.tar.gz
jdk_folder=jdk1.8.0_211


[keyfree_login]
# null,wait for the future
# no use sudouser


[hostname_to_host]
# the means is add at /etc/hosts
# real_hosts and hostname must one-to-one
hostname=cluster1,cluster2,cluster3
real_hosts=192.168.130.196,192.168.130.197,192.168.130.123


[hadoop]
#file for hadoop
hadoop_local_file=package/hadoop-2.8.5.tar.gz
hadoop_folder=hadoop-2.8.5
#config for hadoop
#    data_folder can have multiple directory,use ',' to to separate data_folder and slaves
data_folder=/home/ubuntu/hadoop_data
master_ip=192.168.130.196
slaves=192.168.130.197,192.168.130.123
dfs_replication=1
#dependence
java_home=/home/ubuntu/jdk1.8.0_211


[spark]
#file for spark
spark_local_file=package/spark-2.2.3-bin-hadoop2.7.tgz
spark_folder=spark-2.2.3-bin-hadoop2.7
#config for spark
master_ip=192.168.130.196
master_public_ip=192.168.130.196
slaves=192.168.130.197,192.168.130.123
spark_worker_dir=/home/ubuntu/work
#dependence
java_home=/home/ubuntu/jdk1.8.0_211
#    Can be empty,to set LD_LIBRARY_PATH
hadoop_home=/home/ubuntu/hadoop-2.8.5


[pg]
hosts=192.168.130.196
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file for pg
pg_local_file=package/postgresql-10.10-2-linux-x64-binaries.tar.gz
pg_folder=pgsql
#config for pg
install_path=/opt
data_path=/data/pg_data
max_connections=1000
#config for pg
superuser=pguser
superuser_passwd=123456